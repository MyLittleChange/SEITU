{
    "train_txt_dbs": ["/txt/vcr_train.db/"],
    "train_img_dbs": ["/img/vcr_gt_train/;/img/vcr_train/"],
    "val_txt_db": "/txt/vcr_val.db/",
    "val_img_db": "/img/vcr_gt_val/;/img/vcr_val/",
    "checkpoint": "/pretrain/uniter-large.pt",
    "checkpoint_from": "vcr_pretrain",
    "model_config": "/src/config/uniter-large.json",
    "output_dir": "/debug/vcr/default",
    "max_txt_len": 220,
    "conf_th": 0.2,
    "max_bb": 100,
    "min_bb": 10,
    "num_bb": 36,
    "train_batch_size": 4000,
    "val_batch_size": 10,
    "gradient_accumulation_steps": 5,
    "learning_rate": 6e-05,
    "lr_mul": 1.0,
    "valid_steps": 1000,
    "num_train_steps": 8000,
    "optim": "adamw",
    "betas": [
        0.9,
        0.98
    ],
    "dropout": 0.1,
    "weight_decay": 0.01,
    "grad_norm": 2.0,
    "warmup_steps": 800,
    "seed": 42,
    "fp16": true,
    "n_workers": 4,
    "pin_mem": true,
      "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 1024,
  "initializer_range": 0.02,
  "intermediate_size": 4096,
  "max_position_embeddings": 512,
  "num_attention_heads": 16,
  "num_hidden_layers": 24,
  "type_vocab_size": 2,
  "vocab_size": 28996
}
